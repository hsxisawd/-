# 个人实战爬虫小项目合集
## 1、爬取Steam百度贴吧(难度简单)
### 案例：百度贴吧帖子获取 
**目标url**：https://tieba.baidu.com/f?kw=steam 

**获取内容：**
帖子的列表页：获取前两页的帖子链接
对每个帖子内容进行解析，获取每个帖子第一页的图片，下载到本地 images 文件中

**主要使用到的技术：**

bs4+requests

**代码思路：**

由于网站有限制IP访问频率这一点要注意，还有在源代码加了注释符所以转换为bs4对象时无法对注释符里面的数据进行解析，所以需要讲注释符进行去除，其他没什么大问题，使用ba4进行解析，获取数据

**使用方法：**

更换掉请求头，然后选择爬取的页数(本来只爬取两页，后面改进可以选择页数)，爬取一页会往本地保存html文件，可以解决一部分频率限制问题，但是没大批量的爬取页数，还是需要设置时间休眠或者使用代理ip

## 2、TapTap游戏评论爬取（难度中下）

### 案例：选取 taptap.com 上面的一个手游，爬取其中的评论

**获取评论的内容为：**

评论id、分数、设备、游戏时长、评论创建时间、评论更新时间（这两个时间都要转为日期）、评论内容、点赞量用户 id 、用户名
爬去10页评论，每页10条评论数据，并保存到Excel中

**主要使用到技术：**

requests+pandas（保存数据，没有用于数分）

**代码思路：**

taptap是一个动态网站，需要对他进行抓包，找到api后，进行请求时，出现一个滑块验证，才能拿到数据，一般这种验证的情况，推断会使用cookie进行验证，然后多封装了一些请求参数进行请求，然后就可以拿到json数据了，同样网站也有访问频率限制，使用使用了time模块加随机数进行随机休眠

**使用方法：**

1、请求参数需要重新设置为本机当前的请求参数，每个人都是不同的，而且cookie会有时效限制，如果其他都没问题，还是无法爬取，就是cookie失效了，需要重新刷新网页，把cookie换上去
2、url上面有个app_id参数是游戏的id，不同的游戏只需要更换这个id就可以了

## 3、词霸翻译(难度中)

### 案例：爬取词霸翻译，实现翻译功能

**主要使用到技术：**

requests+hashlib

**代码思路：**

词霸翻译和百度网易翻译有个区别，词霸翻译是在api请求参数sign进行加密，要想拿到数据就必须破解sign加密方式，使用js逆向解析，发现sign和这个代码是有联系的

`r = c()("6key_cibaifanyicjbysdlove1".concat(t.q.replace(/(^\s*)|(\s*$)/g, ""))).toString().substring(0, 16);`

根据加密展示的效果可以判断使用的加密方式是md5加密。代码大致的意思就是将我们输入的翻译文本(就是这个t.q)和6key_cibaifanyicjbysdlove1进行拼接，然后md5加密，再转成字符串截取前16个字符组成的，大致的破解就是这样，然后封装请求参数就可以爬取了

**使用方法：**

1、请求头，尽量换成自己本机的请求头
2、运行就OK了